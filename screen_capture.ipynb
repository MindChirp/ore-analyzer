{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\frikk\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mss in c:\\users\\frikk\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (9.0.2)\n",
      "\n",
      "cpu\n",
      "Loading runs\\detect\\train16\\weights\\best.onnx for ONNX Runtime inference...\n",
      "Preferring ONNX Runtime AzureExecutionProvider\n",
      "\n",
      "0: 640x640 (no detections), 74.7ms\n",
      "Speed: 1.5ms preprocess, 74.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 66.2ms\n",
      "Speed: 2.5ms preprocess, 66.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 54.8ms\n",
      "Speed: 2.0ms preprocess, 54.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 54.2ms\n",
      "Speed: 2.0ms preprocess, 54.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 52.4ms\n",
      "Speed: 2.2ms preprocess, 52.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 51.7ms\n",
      "Speed: 1.5ms preprocess, 51.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 51.2ms\n",
      "Speed: 2.0ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 60.0ms\n",
      "Speed: 1.7ms preprocess, 60.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 49.7ms\n",
      "Speed: 2.5ms preprocess, 49.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 55.5ms\n",
      "Speed: 2.0ms preprocess, 55.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 52.6ms\n",
      "Speed: 2.5ms preprocess, 52.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 49.2ms\n",
      "Speed: 1.0ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 52.7ms\n",
      "Speed: 2.0ms preprocess, 52.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 49.6ms\n",
      "Speed: 1.0ms preprocess, 49.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 51.1ms\n",
      "Speed: 2.5ms preprocess, 51.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 50.1ms\n",
      "Speed: 1.0ms preprocess, 50.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 50.6ms\n",
      "Speed: 2.0ms preprocess, 50.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 48.7ms\n",
      "Speed: 2.5ms preprocess, 48.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 51.5ms\n",
      "Speed: 2.5ms preprocess, 51.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 55.1ms\n",
      "Speed: 1.0ms preprocess, 55.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 55.8ms\n",
      "Speed: 2.5ms preprocess, 55.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 48.4ms\n",
      "Speed: 2.8ms preprocess, 48.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 51.7ms\n",
      "Speed: 1.0ms preprocess, 51.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 50.3ms\n",
      "Speed: 2.0ms preprocess, 50.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 53.8ms\n",
      "Speed: 1.5ms preprocess, 53.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mss() \u001b[38;5;28;01mas\u001b[39;00m sct:\n\u001b[0;32m     46\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     48\u001b[0m     screenshot \u001b[38;5;241m=\u001b[39m sct\u001b[38;5;241m.\u001b[39mgrab(mon) \n\u001b[0;32m     49\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfrombytes(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m, (screenshot\u001b[38;5;241m.\u001b[39mwidth, screenshot\u001b[38;5;241m.\u001b[39mheight), screenshot\u001b[38;5;241m.\u001b[39mrgb)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%pip install mss\n",
    "from model import ImageNetwork\n",
    "import torch\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/train16/weights/best.onnx\")\n",
    "\n",
    "name_map = [\n",
    "  \"coal\",\n",
    "  \"diamond\",\n",
    "  \"emerald\",\n",
    "  \"gold\",\n",
    "  \"iron\",\n",
    "  \"lapis\",\n",
    "  \"nether_gold_ore\",\n",
    "  \"redstone_ore\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "# Set up the image model\n",
    "# model = ImageNetwork()\n",
    "# model.load_state_dict(torch.load('model.pth'))\n",
    "# model.eval()\n",
    "# model.to(device)\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mon = {'left': 160, 'top': 160, 'width': 700, 'height': 700}\n",
    "\n",
    "def show_image(image):\n",
    "    img = Image.fromarray(cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR))\n",
    "    img.show()\n",
    "\n",
    "\n",
    "with mss() as sct:\n",
    "  while True:\n",
    "    time.sleep(1) \n",
    "    screenshot = sct.grab(mon) \n",
    "    img = Image.frombytes('RGB', (screenshot.width, screenshot.height), screenshot.rgb)\n",
    "\n",
    "    # Run the image through the model\n",
    "\n",
    "    predicted = model.predict(img, device=device)\n",
    "    # img_bgr = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    # cv2.imshow('test', img_bgr)\n",
    "    # if cv2.waitKey(33) & 0xFF in (\n",
    "    #     ord('q'), \n",
    "    #     27, \n",
    "    # ):\n",
    "    #     break\n",
    "\n",
    "    for result in predicted:\n",
    "      for box, label in zip(result.boxes, result.names):\n",
    "        print(f'{label}: {box}')\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #   output = model(image)\n",
    "    #   _, predicted = torch.max(output, 1)\n",
    "\n",
    "\n",
    "      \n",
    "    # print(f'Predicted class: {name_map[predicted.item()]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
